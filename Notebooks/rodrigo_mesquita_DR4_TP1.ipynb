{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyuP9gkgBs4mqRo6bArul+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Rodrigo_Mesquita_DR4_TP1**\n",
        "## **Inteligência Artificial: Clusterização [24E2_4]**"
      ],
      "metadata": {
        "id": "zLUXZcnCIpQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Cite e explique dois algoritmos de clusterização baseado em particionamento."
      ],
      "metadata": {
        "id": "7y_Y0L2-JBp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Means**: O K-Means é um algoritimo de clusterizaçao não supervisionado, ou seja, que trabalha com dados não rotulados, os separando em uma quantidade de clusters pré-definida pelo usuário, com base na similaridade/proximidade entre cada amostra. Na primeira iteração o modelo escolhe posições aleatórios para os centróides e relaciona cada amostra ao centróide mais próximo, formando os clusters. Em seguida, recalcula a o posicionamento do centroide baseado na distância euclidiana de todos os pontos que foram atribuidos a ele. A cada iteração posterior o modelo executa novamente o relacionamento das amostras aos centroides e o ajuste do posicionamento, até que a variação de posicionamento do centroide entre cada iteração passe a ser insignificante ou atinja o número máximo de iterações.\n",
        "\n",
        "**K-Medoids**: O K-Medoids também é um algoritimo de clusterização não supervisionado, porém, invés de escolher posições iniciais aleatórias para os centroides, ele escolhe pontos reais do conjunto de dados para servirem como medoides, em seguida atribui cada ponto ao medoide mais próximo com base em uma métrica de dissimilaridade. A cada iteração o modelo escolhe um novo ponto do cluster como medoide e recalcula a métrica para verificar se algum deles, se escolhido como novo medoide, melhoraria o resultado.\n",
        "O K-Medoid possui menor sensibilidade a outliers e é mais adequado para clusters assimétricos, porém possui maior custo operacional."
      ],
      "metadata": {
        "id": "9JLW43HuJqsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Explique o principal algoritmo de clusterização, visto em sala de aula, baseado em densidade.\n"
      ],
      "metadata": {
        "id": "LM5A1fiEJChd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O DB-Scan, diferente dos métodos de particionamento, se baseia na densidade de pontos em uma mesma região. A quantidade de clusters é definida automaticamente baseado na quantidade de regiões com alta densidade de pontos e separadas entre si por espaços de menor densidade. Os pontos mais distantes dessas regiões (outliers) são considerados como ruídos, não sendo alocados em nenhum cluster."
      ],
      "metadata": {
        "id": "tc05mh1lUb3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Utilizando o dataset iris (sklearn.datasets.load_iris), utilize o KMeans e utilizando o método Silhouette, veja qual o número ideal de clusters. Faça uma conclusão dessa avaliação.\n"
      ],
      "metadata": {
        "id": "aLMyW5TwJEA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6aZcStyDIiz1"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data"
      ],
      "metadata": {
        "id": "E_LvHGJtp93g"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette = []\n",
        "\n",
        "for i in range(2, 11):\n",
        "    kmeans = KMeans(n_clusters= i, random_state=33)\n",
        "    kmeans.fit(X)\n",
        "    preds = kmeans.labels_\n",
        "    silhouette.append(silhouette_score(X,preds))"
      ],
      "metadata": {
        "id": "rwsu9mF3qB7J",
        "outputId": "fda027b4-b913-4247-abcd-3042b5bb7da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qtd_ideal = silhouette.index(max(silhouette)) + 2\n",
        "print(f'O número ideal de clusters é: {qtd_ideal}, com score de {max(silhouette)*100:.2f}%')"
      ],
      "metadata": {
        "id": "yBh0xw2OvLkA",
        "outputId": "1910b539-e915-4c49-edba-4ae4b3eac953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número ideal de clusters é: 2, com score de 68.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Utilizando o dataset iris (sklearn.datasets.load_iris), faça a redução de dimensionalidade utilizando KMeans e o PCA, utilize o modelo de regressão logística para comparar os resultados"
      ],
      "metadata": {
        "id": "eazFuvnFJFUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "XLDCFdRiortg"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "0tJgJKuazOv4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redução de dimensionalidade com KMeans\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "X_kmeans = kmeans.transform(X)"
      ],
      "metadata": {
        "id": "DGQlWoB_zQEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redução de dimensionalidade com PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "hcadhzOUzRS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir os dados em conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "akq_Mr0DzThh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Regressão Logística sem redução de dimensionalidade\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(f'Acurácia da Regressão Logística sem redução de dimensionalidade: {accuracy_lr}')"
      ],
      "metadata": {
        "id": "hMGHjlwvzVEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Regressão Logística com redução de dimensionalidade usando KMeans\n",
        "lr_kmeans = LogisticRegression()\n",
        "lr_kmeans.fit(X_kmeans, y)\n",
        "X_test_kmeans = kmeans.transform(X_test)\n",
        "y_pred_lr_kmeans = lr_kmeans.predict(X_test_kmeans)\n",
        "accuracy_lr_kmeans = accuracy_score(y_test, y_pred_lr_kmeans)\n",
        "print(f'Acurácia da Regressão Logística com redução de dimensionalidade usando KMeans: {accuracy_lr_kmeans}')"
      ],
      "metadata": {
        "id": "4BIgVuGQzWbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Regressão Logística com redução de dimensionalidade usando PCA\n",
        "lr_pca = LogisticRegression()\n",
        "lr_pca.fit(X_pca, y)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "y_pred_lr_pca = lr_pca.predict(X_test_pca)\n",
        "accuracy_lr_pca = accuracy_score(y_test, y_pred_lr_pca)\n",
        "print(f'Acurácia da Regressão Logística com redução de dimensionalidade usando PCA: {accuracy_lr_pca}')"
      ],
      "metadata": {
        "id": "dFbbWk5lzYKJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}