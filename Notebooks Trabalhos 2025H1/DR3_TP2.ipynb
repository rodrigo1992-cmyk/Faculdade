{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4e33ed",
   "metadata": {},
   "source": [
    "### 1. Você está configurando um ambiente de Big Data para uma empresa e precisa demonstrar o uso básico de várias ferramentas. Para cada uma das seguintes tecnologias, escreva o comando ou script necessário para realizar a tarefa especificada: \n",
    "- Apache Hive, crie uma tabela chamada \"produtos\" com as colunas id (INT), nome (STRING) e preco (FLOAT); \n",
    "- Hadoop HDFS, copie um arquivo local chamado \"dados.csv\" para o diretório \"/input\" no HDFS; \n",
    "- Apache Pig: carregue dados de um arquivo CSV chamado \"vendas.csv\" com três colunas: id, produto e valor.\n",
    "\n",
    "### 2. Em um projeto de implementação de Big Data, você precisa executar consultas básicas em diferentes ferramentas. Para cada tecnologia, escreva uma consulta ou comando para realizar a tarefa especificada: \n",
    "- Apache Hive, selecione todos os produtos da tabela \"produtos\" onde o preço é maior que 100; \n",
    "- Hadoop HDFS, liste todos os arquivos no diretório \"/input\" do HDFS; \n",
    "- Apache Pig, filtre as vendas do arquivo \"vendas.csv\" para mostrar apenas aquelas com valor acima de 500.\n",
    "\n",
    "### 3. Em um projeto de Big Data, você precisa carregar dados em diferentes ferramentas. Para cada tecnologia abaixo, escreva um comando ou script para realizar a tarefa de carregamento de dados especificada: \n",
    "- Apache Hive, carregue dados de um arquivo CSV chamado \"vendas.csv\" para uma tabela Hive chamada \"vendas\" com as colunas: id (INT), produto (STRING), valor (FLOAT); \n",
    "- Hadoop HDFS, carregue um arquivo local \"clientes.txt\" para o diretório \"/data\" no HDFS; \n",
    "- Apache Spark, leia um arquivo JSON chamado \"config.json\" e crie um DataFrame.\n",
    "\n",
    "### 4. Você precisa realizar operações de transformação de dados em diferentes ferramentas. Para cada tecnologia, escreva um comando ou script para realizar a tarefa de transformação especificada: \n",
    "- Apache Hive, crie uma nova tabela \"vendas_resumo\" que contenha o total de vendas por produto a partir da tabela \"vendas\" (id INT, produto STRING, valor FLOAT); \n",
    "- Apache Pig, agrupe os dados do arquivo \"logs.csv\" (colunas: data, ip, url) por URL e conte o número de acessos para cada URL; \n",
    "- Apache Spark, usando um DataFrame \"df\" criado a partir de \"vendas.csv\" (colunas: id, produto, valor), calcule o valor total de vendas por produto.\n",
    "\n",
    "### 5. Em um projeto de implementação de Big Data utilizando o ecossistema Hadoop, você precisa demonstrar o entendimento do conceito de ETL/ELT. Para cada tecnologia, descreva uma tarefa simples de ETL ou ELT: \n",
    "- Apache Hive, descreva como você usaria o Hive para extrair dados de uma tabela \"vendas_brutas\", transformar calculando o total de vendas por produto, e carregar em uma nova tabela \"vendas_resumo\"; \n",
    "- Hadoop HDFS e MapReduce, explique como você implementaria um processo ETL para contar palavras em arquivos de texto armazenados no HDFS; \n",
    "- Apache Pig, explique como você usaria o Pig para realizar um processo ETL que filtra registros de log e calcula estatísticas básicas.\n",
    "\n",
    "### 6. Para importar dados de um banco de dados SQL Server para o ecossistema Hadoop, utilizando Apache Spark, como você escreveria um código PySpark para ler os dados de uma tabela chamada \"clientes\" diretamente do SQL Server.\n",
    "\n",
    "### 7. Em um projeto de Big Data utilizando HBase, você precisa realizar operações básicas e integrar o HBase com outras ferramentas do ecossistema Hadoop. Para cada item, escreva um comando ou explique brevemente como realizaria a tarefa: \n",
    "- HBase, crie uma tabela chamada \"clientes\" com uma família de colunas chamada \"info\"; \n",
    "- HBase, insira um novo registro na tabela \"clientes\" com a chave de linha \"1001\", nome \"Alice\" e email \"alice@email.com\"; \n",
    "- Apache Pig, escreva um script Pig para ler dados da tabela \"clientes\" do HBase.\n",
    "\n",
    "### 8. Utilizando o HBase, você precisa configurar e gerenciar tabelas. Para cada item, escreva um comando ou explique brevemente como realizaria a tarefa: crie uma tabela chamada \"vendas\" com duas famílias de colunas: \"info\" e \"detalhes\", altere a tabela \"vendas\" para adicionar uma nova família de colunas chamada \"estatísticas\", liste todas as tabelas existentes no HBase e mostre a estrutura detalhada da tabela \"vendas\"."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
